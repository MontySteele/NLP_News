{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Monty's NLP work - identify news tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqy889e-JhcE",
        "colab_type": "code",
        "outputId": "842b12a0-4b3a-4151-b02b-1e47fc0bcd48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install tensorflow-hub\n",
        "!pip install tfds-nightly\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.18.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (46.0.0)\n",
            "Collecting tfds-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/09/3be889b6ef8424273d10a03b206d933290e9148d82c9cf97ed1cee7dbdcd/tfds_nightly-2.1.0.dev202003300105-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.21.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (3.10.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.21.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (1.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (0.3.1.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (19.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tfds-nightly) (4.38.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tfds-nightly) (1.51.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tfds-nightly) (46.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
            "Installing collected packages: tfds-nightly\n",
            "Successfully installed tfds-nightly-2.1.0.dev202003300105\n",
            "Version:  2.2.0-rc1\n",
            "Eager mode:  True\n",
            "Hub version:  0.7.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP8LFoK09MXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using google colab - this first step is for loading in the data from my personal Drive\n",
        "\n",
        "# Login with google credentials\n",
        "\n",
        "from pydrive.auth import GoogleAuth \n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Handle errors from too many requests\n",
        "\n",
        "import logging\n",
        "logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)\n",
        "\n",
        "# The ID for my personal Drive folder is 1BVUuroPvozFxMjMIYrGOFtI4r6erSBCx\n",
        "# I am now listing the ID numbers for the files in this folder to find the data files\n",
        "\n",
        "#file_list = drive.ListFile({'q': \"'1BVUuroPvozFxMjMIYrGOFtI4r6erSBCx' in parents and trashed=false\"}).GetList()\n",
        "#for file1 in file_list:\n",
        "#  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "\n",
        "\n",
        "# Now that I have the ID files, load the files\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1mZ2VUPqvPujfO87V9u8_mH_ugTTWDFxml-TDJcO6qeA/edit#gid=906545618')\n",
        "sheet = wb.sheet1\n",
        "data = sheet.get_all_values()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjaFhYDAxd54",
        "colab_type": "code",
        "outputId": "294fe584-bda9-43f0-8412-515e883913a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# Import NTLK libraries\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP-zBwTZ-15o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert DF to Pandas, remove top row with column IDs, limit to only labelled entries\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.columns = df.iloc[0]\n",
        "df = df.iloc[1:]\n",
        "df = df[:700]\n",
        "#df['Label'], df['Tweet']\n",
        "\n",
        "df = df.reset_index()\n",
        "\n",
        "target = df['Label'].astype(int)\n",
        "tweets = df['Tweet'].copy(deep=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMOdRcgP0XkM",
        "colab_type": "code",
        "outputId": "974287f5-46b9-4224-d5f0-d1b957c3c3fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "target.describe()\n",
        "\n",
        "# 34% are 0, then 66% are 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    700.000000\n",
              "mean       0.341429\n",
              "std        0.474528\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000\n",
              "Name: Label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQB7qBR5g5ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wn = nltk.WordNetLemmatizer()\n",
        "import string\n",
        "\n",
        "## Function to clean entries - lowercase, lemmatize, tokenize, drop stop words, recombine\n",
        "\n",
        "def clean_articles(doc):\n",
        "    for column in range(len(doc)):\n",
        "        \n",
        "        #doc[column] = doc[column].astype(str)\n",
        "        doc[column] = doc[column].replace('[^\\w\\s]','')\n",
        "        \n",
        "        doc[column] = doc[column].lower()\n",
        "        # removing punctuation worsens results a lot\n",
        "        #doc[column] = ''.join([str(item) for item in doc[column] if item not in string.punctuation])\n",
        "        \n",
        "        #doc[column] = doc[column].replace(np.nan, ' ', regex=True)\n",
        "\n",
        "        doc[column] = nltk.word_tokenize(doc[column])\n",
        "        doc[column] = lemmatize_text(doc[column])\n",
        "\n",
        "        doc[column] = [token for token in doc[column] if token not in stop_words]     \n",
        "        doc[column] = ' '.join([str(item) for item in doc[column] ])\n",
        "    return doc\n",
        "\n",
        "def lemmatize_text(tokenized_text):\n",
        "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCBnMBxyhsq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get cleaned data\n",
        "data_clean = clean_articles(tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T250zSl_NDVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reunify cleaned data and target\n",
        "\n",
        "merge_df = pd.concat([data_clean, target], axis=1, sort=False)\n",
        "\n",
        "# shuffle the data\n",
        "\n",
        "train_shuffle_0 = merge_df[merge_df[\"Label\"] == 0].sample(frac=0.8, random_state=np.random.seed())\n",
        "train_shuffle_1 = merge_df[merge_df[\"Label\"] == 1].sample(frac=0.8, random_state=np.random.seed())\n",
        "\n",
        "test_shuffle_0 = merge_df[merge_df[\"Label\"] == 0].drop(train_shuffle_0.index)\n",
        "test_shuffle_1 = merge_df[merge_df[\"Label\"] == 1].drop(train_shuffle_1.index)\n",
        "\n",
        "train_shuffle = pd.concat([train_shuffle_0, train_shuffle_1], axis=0, sort=False).sample(frac=1)\n",
        "test_shuffle = pd.concat([test_shuffle_0, test_shuffle_1], axis=0, sort=False).sample(frac=1)\n",
        "\n",
        "data_clean_train = train_shuffle['Tweet']\n",
        "data_clean_test = test_shuffle['Tweet']\n",
        "\n",
        "# train test split\n",
        "\n",
        "target_train = train_shuffle['Label']\n",
        "target_test = test_shuffle['Label']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpu7R2A5giEs",
        "colab_type": "code",
        "outputId": "b2245428-f3d9-499e-fb7c-630e8ef32598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "target_test.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    140.000000\n",
              "mean       0.342857\n",
              "std        0.476369\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000\n",
              "Name: Label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1n250PZwOqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert pandas to TF data - thanks ben\n",
        "train_data = (\n",
        "    tf.data.Dataset.from_tensor_slices(\n",
        "        (\n",
        "            tf.cast(data_clean_train.values, tf.string),\n",
        "            tf.cast(target_train.values, tf.int32)\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "test_data = (\n",
        "    tf.data.Dataset.from_tensor_slices(\n",
        "        (\n",
        "            tf.cast(data_clean_test.values, tf.string),\n",
        "            tf.cast(target_test.values, tf.int32)\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "train_data = train_data.shuffle(5000).batch(32)\n",
        "test_data = test_data.shuffle(5000).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48F2BYmoLuF2",
        "colab_type": "code",
        "outputId": "1692aa87-52b9-4ee0-9482-3bb4bd874718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "## Transfer learning\n",
        "\n",
        "#embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\", output_shape=[],\n",
        "                           input_shape=[], dtype=tf.string)\n",
        "\n",
        "## Set up model\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(1000, activation ='relu'))\n",
        "model.add(tf.keras.layers.Dense(200, activation ='relu'))\n",
        "keras.layers.Dropout(0.2, noise_shape=None, seed=None)\n",
        "model.add(tf.keras.layers.Dense(16, activation ='relu'))\n",
        "keras.layers.Dropout(0.2, noise_shape=None, seed=None)\n",
        "model.add(tf.keras.layers.Dense(1, activation ='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_6 (KerasLayer)   (None, 128)               124642688 \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              129000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 200)               200200    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                3216      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 124,975,121\n",
            "Trainable params: 332,433\n",
            "Non-trainable params: 124,642,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHB2bs8YNnxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss =tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['binary_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BccPiVPCOOB4",
        "colab_type": "code",
        "outputId": "a113314d-eff8-419d-fe32-dae363998b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_data, epochs=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.7269 - binary_accuracy: 0.6464\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6766 - binary_accuracy: 0.6589\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6598 - binary_accuracy: 0.6589\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6541 - binary_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6469 - binary_accuracy: 0.8625\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6405 - binary_accuracy: 0.8821\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6198 - binary_accuracy: 0.9143\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6006 - binary_accuracy: 0.9393\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5976 - binary_accuracy: 0.9446\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5943 - binary_accuracy: 0.9429\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5908 - binary_accuracy: 0.9393\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5833 - binary_accuracy: 0.9554\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5777 - binary_accuracy: 0.9625\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5763 - binary_accuracy: 0.9679\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5802 - binary_accuracy: 0.9679\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5754 - binary_accuracy: 0.9696\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5792 - binary_accuracy: 0.9696\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5752 - binary_accuracy: 0.9696\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5781 - binary_accuracy: 0.9714\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5754 - binary_accuracy: 0.9714\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5758 - binary_accuracy: 0.9714\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5751 - binary_accuracy: 0.9714\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5745 - binary_accuracy: 0.9714\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5779 - binary_accuracy: 0.9714\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5738 - binary_accuracy: 0.9714\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5757 - binary_accuracy: 0.9714\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5751 - binary_accuracy: 0.9714\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5757 - binary_accuracy: 0.9714\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5757 - binary_accuracy: 0.9714\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5764 - binary_accuracy: 0.9714\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5751 - binary_accuracy: 0.9714\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5770 - binary_accuracy: 0.9714\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5770 - binary_accuracy: 0.9714\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5744 - binary_accuracy: 0.9714\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5777 - binary_accuracy: 0.9714\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5768 - binary_accuracy: 0.9714\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5784 - binary_accuracy: 0.9714\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5770 - binary_accuracy: 0.9714\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5731 - binary_accuracy: 0.9714\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5750 - binary_accuracy: 0.9714\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5737 - binary_accuracy: 0.9714\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5768 - binary_accuracy: 0.9714\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5770 - binary_accuracy: 0.9714\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5750 - binary_accuracy: 0.9714\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5757 - binary_accuracy: 0.9714\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5737 - binary_accuracy: 0.9714\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5781 - binary_accuracy: 0.9714\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5750 - binary_accuracy: 0.9714\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5757 - binary_accuracy: 0.9714\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5744 - binary_accuracy: 0.9714\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5761 - binary_accuracy: 0.9714\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5764 - binary_accuracy: 0.9714\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5757 - binary_accuracy: 0.9714\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5764 - binary_accuracy: 0.9714\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5737 - binary_accuracy: 0.9714\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5757 - binary_accuracy: 0.9714\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5750 - binary_accuracy: 0.9714\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5750 - binary_accuracy: 0.9714\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5750 - binary_accuracy: 0.9714\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5744 - binary_accuracy: 0.9714\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5755 - binary_accuracy: 0.9714\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5750 - binary_accuracy: 0.9714\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5763 - binary_accuracy: 0.9714\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5782 - binary_accuracy: 0.9714\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5831 - binary_accuracy: 0.9589\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5835 - binary_accuracy: 0.9536\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5819 - binary_accuracy: 0.9554\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5815 - binary_accuracy: 0.9571\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5869 - binary_accuracy: 0.9536\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5823 - binary_accuracy: 0.9643\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5820 - binary_accuracy: 0.9589\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5838 - binary_accuracy: 0.9536\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5773 - binary_accuracy: 0.9643\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5801 - binary_accuracy: 0.9625\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5778 - binary_accuracy: 0.9661\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5745 - binary_accuracy: 0.9696\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5777 - binary_accuracy: 0.9714\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5737 - binary_accuracy: 0.9732\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5728 - binary_accuracy: 0.9750\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5744 - binary_accuracy: 0.9750\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5751 - binary_accuracy: 0.9750\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5751 - binary_accuracy: 0.9750\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5744 - binary_accuracy: 0.9750\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5757 - binary_accuracy: 0.9750\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5744 - binary_accuracy: 0.9750\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5731 - binary_accuracy: 0.9750\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5717 - binary_accuracy: 0.9750\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5755 - binary_accuracy: 0.9750\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5764 - binary_accuracy: 0.9750\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5724 - binary_accuracy: 0.9750\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5764 - binary_accuracy: 0.9750\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5768 - binary_accuracy: 0.9750\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5737 - binary_accuracy: 0.9750\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5731 - binary_accuracy: 0.9750\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5750 - binary_accuracy: 0.9750\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5757 - binary_accuracy: 0.9750\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5750 - binary_accuracy: 0.9750\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5737 - binary_accuracy: 0.9750\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5737 - binary_accuracy: 0.9750\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5750 - binary_accuracy: 0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhXoBMZXPRJr",
        "colab_type": "code",
        "outputId": "688e5d89-a585-49db-8042-bd21264f8788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "results = model.evaluate(test_data, verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 - 0s - loss: 0.6039 - binary_accuracy: 0.8929\n",
            "loss: 0.604\n",
            "binary_accuracy: 0.893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaT0tbV9Py72",
        "colab_type": "code",
        "outputId": "68a30abf-d22d-412f-e3b4-e4e49a2956c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6038973927497864, 0.8928571343421936]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoSj6MpwTpHu",
        "colab_type": "code",
        "outputId": "f34788de-4336-4d04-bb0e-87fa9693a282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict([\"I hated it\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.7867325e-34]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5e6a5ca1-9e12-4b5b-d683-c1c025e94f19",
        "id": "IwpYzTcFUHTB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict([\"loved it!\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.8276788e-21]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "416213f9-abde-4e4a-ce1f-83758aa54bdd",
        "id": "0ViwrJMGUO6k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict([\"It Was a glorious triumph\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.9321082e-36]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXJG-loiUSnH",
        "colab_type": "code",
        "outputId": "6a52986d-9489-430e-faee-8ac9eb1ec0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict([\"I thought it Was a glorious piece of complete crap!\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.854035e-31]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmIyjgZqUhz5",
        "colab_type": "code",
        "outputId": "66c7742f-41a1-43c8-c005-057e40ffb490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "model.predict_classes([\"It was great\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-81e497d7d1cc>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-81e497d7d1cc>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJpLTV7-UuB3",
        "colab_type": "code",
        "outputId": "e0e0f18e-2910-4fc1-e3ba-438c83da00a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict_classes([\"It was shit\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1e583b91-1f17-46f0-e074-6302d0a618e6",
        "id": "zX8aihAq_3r_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "source": [
        "## Confusion matrix - not working\n",
        "\n",
        "y_pred=model.predict_classes(test_data).reshape(len(model.predict_classes(test_data),))\n",
        "\n",
        "con_mat = tf.math.confusion_matrix(labels=target_test, predictions=y_pred).numpy()\n",
        "#con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "con_mat_df = pd.DataFrame(con_mat)\n",
        "\n",
        "con_mat_df\n",
        "import seaborn as sns\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "\n",
        "y_pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAJGCAYAAABrz54hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}